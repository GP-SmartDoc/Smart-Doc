from langchain.messages import SystemMessage, HumanMessage
from src.config.model import model
import src.config.summarization_prompts as prompts
import src.config.qa_prompts as qprompts
import json
from src.utils.strings import clean_json_string

def image_micro_agent(state: dict, model):
    captions = state.get("image_captions", [])
    if not captions:
        return {"image_answers": [], "llm_calls": 0}

    detail_level = state.get("detail_level", 2)

    # Limit sentences per caption based on detail level
    sentences_per_caption = {1: 1, 2: 2, 3: 4}
    max_sents = sentences_per_caption.get(detail_level, 2)

    # Build merged description
    merged_caption = "\n".join(
        f"- Region {i+1}: {cap}" for i, cap in enumerate(captions)
    )
    system_prompt = prompts.IA_SYSTEM_PROMPT
    resp = model.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"""
User Question:
{state.get('user_question', '')}

Image Descriptions:
{merged_caption}

Detail Level: {detail_level} (Max {max_sents} sentences per image)
""")
    ])

    return {
        "image_answers": [resp.content],
        "llm_calls": 1
    }

def image_modality_agent(state: dict, model):
    intent = state.get("intent", "qa")

    # Retrieve the image answers generated by the micro agent
    image_answers = state.get("image_answers", [])

    # ---------------------------
    # Early Exit Fix
    # If image_micro_agent produced nothing, cleanly skip by passing an empty string
    # to the correct state key based on the active intent.
    # ---------------------------
    if not image_answers:
        out_key = "image_summary" if intent == "summary" else "image_answer"
        return {
            out_key: "",
            "llm_calls": 0
        }

    # Merge micro reasoning into single evidence block
    image_text = "\n".join(image_answers)

    if intent == "summary":
        system_prompt = prompts.IA_MODALITY_SYSTEM_PROMPT
        payload = {
            "question": state.get("user_question", ""),
            "image_evidence": image_text
        }
        out_key = "image_summary"
    else:
        system_prompt = qprompts.QA_GA_SYSTEM_PROMPT
        payload = {
            "question": state.get("user_question", ""),
            "image_evidence": image_text
        }
        out_key = "image_answer"

    resp = model.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=json.dumps(payload))
    ])

    return {
        out_key: resp.content,
        "llm_calls": 1
    }